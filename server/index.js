const express = require('express')
const multer = require('multer')
const cors = require('cors')
const csv = require('csv-parser')
const fs = require('fs')
const path = require('path')
const { Worker } = require('worker_threads')
const WebSocket = require('ws')

const app = express()
const PORT = process.env.PORT || 3002

// Middleware
app.use(cors())
app.use(express.json())

// WebSocket ัะตัะฒะตั ะดะปั ะฟัะพะณัะตััะฐ
const wss = new WebSocket.Server({ port: 8080 })

// ะฅัะฐะฝะธะปะธัะต ะฐะบัะธะฒะฝัั ะทะฐะดะฐั
const jobs = new Map()

// ะะฐัััะพะนะบะฐ multer ะดะปั ะทะฐะณััะทะบะธ ัะฐะนะปะพะฒ
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const uploadDir = path.join(__dirname, 'uploads')
    if (!fs.existsSync(uploadDir)) {
      fs.mkdirSync(uploadDir, { recursive: true })
    }
    cb(null, uploadDir)
  },
  filename: (req, file, cb) => {
    const uniqueName = `${Date.now()}-${Math.round(Math.random() * 1E9)}-${file.originalname}`
    cb(null, uniqueName)
  }
})

const upload = multer({ 
  storage,
  limits: { 
    fileSize: 100 * 1024 * 1024 // 100MB
  },
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'text/csv' || file.originalname.toLowerCase().endsWith('.csv')) {
      cb(null, true)
    } else {
      cb(new Error('ะขะพะปัะบะพ CSV ัะฐะนะปั ัะฐะทัะตัะตะฝั'))
    }
  }
})

// ะฃัะธะปะธัะฐ ะดะปั ะณะตะฝะตัะฐัะธะธ ID ะทะฐะดะฐั
function generateJobId() {
  return `job_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
}

// ะคัะฝะบัะธั ะดะปั ะพัะฟัะฐะฒะบะธ ะฟัะพะณัะตััะฐ ัะตัะตะท WebSocket
function broadcastProgress(jobId, progress) {
  const message = JSON.stringify({ jobId, progress })
  wss.clients.forEach(client => {
    if (client.readyState === WebSocket.OPEN) {
      client.send(message)
    }
  })
}

// API endpoint ะดะปั ะทะฐะณััะทะบะธ ะธ ะพะฑัะฐะฑะพัะบะธ CSV
app.post('/api/analytics/upload', upload.single('csvFile'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'ะคะฐะนะป ะฝะต ะทะฐะณััะถะตะฝ' })
    }

    const { provider = 'optipay' } = req.body
    const jobId = generateJobId()
    const filePath = req.file.path

    console.log(`๐ ะะพะฒะฐั ะทะฐะดะฐัะฐ: ${jobId}, ัะฐะนะป: ${req.file.originalname}, ะฟัะพะฒะฐะนะดะตั: ${provider}`)

    // ะกะพะทะดะฐะตะผ ะทะฐะฟะธัั ะพ ะทะฐะดะฐัะต
    jobs.set(jobId, {
      id: jobId,
      status: 'processing',
      fileName: req.file.originalname,
      fileSize: req.file.size,
      provider,
      startTime: new Date(),
      progress: 0,
      stage: 'ะะพะดะณะพัะพะฒะบะฐ ะบ ะพะฑัะฐะฑะพัะบะต...'
    })

    // ะัะฟัะฐะฒะปัะตะผ ะฝะตะผะตะดะปะตะฝะฝัะน ะพัะฒะตั ั ID ะทะฐะดะฐัะธ
    res.json({
      jobId,
      status: 'processing',
      message: 'ะคะฐะนะป ะทะฐะณััะถะตะฝ, ะฝะฐัะธะฝะฐะตััั ะพะฑัะฐะฑะพัะบะฐ'
    })

    // ะะฐะฟััะบะฐะตะผ ะพะฑัะฐะฑะพัะบั ะฒ ัะพะฝะต
    processCSVFile(jobId, filePath, provider)

  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ ะทะฐะณััะทะบะธ:', error)
    res.status(500).json({ error: error.message })
  }
})

// API endpoint ะดะปั ะฟะพะปััะตะฝะธั ััะฐัััะฐ ะทะฐะดะฐัะธ
app.get('/api/analytics/job/:jobId/status', (req, res) => {
  const { jobId } = req.params
  const job = jobs.get(jobId)

  if (!job) {
    return res.status(404).json({ error: 'ะะฐะดะฐัะฐ ะฝะต ะฝะฐะนะดะตะฝะฐ' })
  }

  res.json(job)
})

// API endpoint ะดะปั ะฟะพะปััะตะฝะธั ัะตะทัะปััะฐัะพะฒ
app.get('/api/analytics/job/:jobId/results', (req, res) => {
  const { jobId } = req.params
  const { page = 1, limit = 100 } = req.query
  
  const job = jobs.get(jobId)
  if (!job || job.status !== 'completed') {
    return res.status(404).json({ error: 'ะะตะทัะปััะฐัั ะฝะต ะณะพัะพะฒั' })
  }

  // ะะฐะณะธะฝะฐัะธั ัะตะทัะปััะฐัะพะฒ
  const startIndex = (page - 1) * limit
  const endIndex = startIndex + parseInt(limit)
  
  const paginatedData = job.results.data.slice(startIndex, endIndex)
  
  res.json({
    data: paginatedData,
    pagination: {
      page: parseInt(page),
      limit: parseInt(limit),
      total: job.results.data.length,
      totalPages: Math.ceil(job.results.data.length / limit)
    },
    metrics: job.results.metrics,
    processingTime: job.processingTime
  })
})

// ะคัะฝะบัะธั ะพะฑัะฐะฑะพัะบะธ CSV ัะฐะนะปะฐ
async function processCSVFile(jobId, filePath, provider) {
  const job = jobs.get(jobId)
  
  try {
    broadcastProgress(jobId, { stage: 'ะงัะตะฝะธะต ัะฐะนะปะฐ...', progress: 10 })
    job.stage = 'ะงัะตะฝะธะต ัะฐะนะปะฐ...'
    job.progress = 10

    // ะะพะดััะธััะฒะฐะตะผ ะพะฑัะตะต ะบะพะปะธัะตััะฒะพ ัััะพะบ ะดะปั ะฟัะพะณัะตััะฐ
    const totalLines = await countLines(filePath)
    console.log(`๐ ะะฑัะตะต ะบะพะปะธัะตััะฒะพ ัััะพะบ: ${totalLines}`)

    broadcastProgress(jobId, { stage: 'ะะฐััะธะฝะณ ะดะฐะฝะฝัั...', progress: 20 })
    job.stage = 'ะะฐััะธะฝะณ ะดะฐะฝะฝัั...'
    job.progress = 20

    const data = []
    let processedLines = 0

    // ะะพัะพะบะพะฒะพะต ััะตะฝะธะต CSV
    const stream = fs.createReadStream(filePath)
      .pipe(csv())
      .on('data', (row) => {
        // ะะพัะผะฐะปะธะทัะตะผ ะดะฐะฝะฝัะต ะฒ ะทะฐะฒะธัะธะผะพััะธ ะพั ะฟัะพะฒะฐะนะดะตัะฐ
        const normalizedRow = normalizeDataRow(row, provider)
        data.push(normalizedRow)
        
        processedLines++
        
        // ะะฑะฝะพะฒะปัะตะผ ะฟัะพะณัะตัั ะบะฐะถะดัะต 1000 ัััะพะบ
        if (processedLines % 1000 === 0) {
          const progress = Math.min(20 + (processedLines / totalLines) * 60, 80)
          broadcastProgress(jobId, { 
            stage: `ะะฑัะฐะฑะพัะฐะฝะพ ${processedLines} ะธะท ${totalLines} ะทะฐะฟะธัะตะน...`, 
            progress 
          })
          job.progress = progress
          job.stage = `ะะฑัะฐะฑะพัะฐะฝะพ ${processedLines} ะธะท ${totalLines} ะทะฐะฟะธัะตะน...`
        }
      })
      .on('end', async () => {
        console.log(`โ ะะฐััะธะฝะณ ะทะฐะฒะตััะตะฝ: ${data.length} ะทะฐะฟะธัะตะน`)
        
        broadcastProgress(jobId, { stage: 'ะััะธัะปะตะฝะธะต ะฐะฝะฐะปะธัะธะบะธ...', progress: 85 })
        job.stage = 'ะััะธัะปะตะฝะธะต ะฐะฝะฐะปะธัะธะบะธ...'
        job.progress = 85

        // ะััะธัะปัะตะผ ะผะตััะธะบะธ
        const metrics = calculateAdvancedMetrics(data, provider)
        
        broadcastProgress(jobId, { stage: 'ะะฐะฒะตััะตะฝะธะต...', progress: 95 })
        job.stage = 'ะะฐะฒะตััะตะฝะธะต...'
        job.progress = 95

        // ะกะพััะฐะฝัะตะผ ัะตะทัะปััะฐัั
        job.status = 'completed'
        job.progress = 100
        job.stage = 'ะะพัะพะฒะพ'
        job.endTime = new Date()
        job.processingTime = job.endTime - job.startTime
        job.results = {
          data,
          metrics,
          totalRecords: data.length
        }

        broadcastProgress(jobId, { 
          stage: 'ะะพัะพะฒะพ!', 
          progress: 100,
          completed: true,
          metrics: metrics
        })

        // ะัะธัะฐะตะผ ัะฐะนะป ัะตัะตะท ัะฐั
        setTimeout(() => {
          fs.unlink(filePath, (err) => {
            if (err) console.error('ะัะธะฑะบะฐ ัะดะฐะปะตะฝะธั ัะฐะนะปะฐ:', err)
            else console.log(`๐๏ธ ะคะฐะนะป ัะดะฐะปะตะฝ: ${filePath}`)
          })
        }, 60 * 60 * 1000)

        console.log(`๐ ะะฐะดะฐัะฐ ${jobId} ะทะฐะฒะตััะตะฝะฐ ะทะฐ ${job.processingTime}ะผั`)
      })
      .on('error', (error) => {
        console.error(`โ ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ ${jobId}:`, error)
        job.status = 'failed'
        job.error = error.message
        broadcastProgress(jobId, { 
          stage: 'ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ', 
          progress: 0, 
          error: error.message 
        })
      })

  } catch (error) {
    console.error(`โ ะัะธัะธัะตัะบะฐั ะพัะธะฑะบะฐ ${jobId}:`, error)
    job.status = 'failed'
    job.error = error.message
    broadcastProgress(jobId, { 
      stage: 'ะัะธัะธัะตัะบะฐั ะพัะธะฑะบะฐ', 
      progress: 0, 
      error: error.message 
    })
  }
}

// ะฃัะธะปะธัะฐ ะดะปั ะฟะพะดััะตัะฐ ัััะพะบ ะฒ ัะฐะนะปะต
function countLines(filePath) {
  return new Promise((resolve, reject) => {
    let lineCount = 0
    fs.createReadStream(filePath)
      .on('data', (buffer) => {
        let idx = -1
        lineCount-- // Because the loop will run once for idx=-1
        do {
          idx = buffer.indexOf(10, idx + 1)
          lineCount++
        } while (idx !== -1)
      })
      .on('end', () => resolve(lineCount))
      .on('error', reject)
  })
}

// ะะพัะผะฐะปะธะทะฐัะธั ะดะฐะฝะฝัั ะฟะพ ะฟัะพะฒะฐะนะดะตัั
function normalizeDataRow(row, provider) {
  const cleanRow = {}
  
  // ะัะธัะฐะตะผ BOM ัะธะผะฒะพะปั ะธะท ะบะปััะตะน
  Object.keys(row).forEach(key => {
    const cleanKey = key.replace(/^\uFEFF/, '').trim()
    cleanRow[cleanKey] = row[key]
  })

  if (provider === 'payshack') {
    return {
      trackingId: cleanRow['Transaction Id'] || cleanRow['Order Id'] || '',
      status: cleanRow['Status'] || '',
      amount: parseFloat(cleanRow['Amount']) || 0,
      createdAt: cleanRow['Created Date'] || '',
      paymentMethod: cleanRow['Payment Method'] || '',
      currency: 'INR',
      provider: 'payshack',
      originalData: cleanRow
    }
  } else {
    // Optipay ัะพัะผะฐั
    return {
      trackingId: cleanRow['Tracking Id'] || '',
      status: cleanRow['Status'] || '',
      amount: parseFloat(cleanRow['Amount']) || 0,
      createdAt: cleanRow['Creation time'] || '',
      paymentMethod: cleanRow['Payment method'] || '',
      company: cleanRow['Company'] || '',
      currency: 'TRY',
      provider: 'optipay',
      originalData: cleanRow
    }
  }
}

// ะะฐััะธัะตะฝะฝัะต ะผะตััะธะบะธ
function calculateAdvancedMetrics(data, provider) {
  const total = data.length
  
  // ะคัะฝะบัะธะธ ะดะปั ะพะฟัะตะดะตะปะตะฝะธั ััะฐัััะพะฒ
  const isSuccessful = (row) => {
    const status = row.status.toLowerCase()
    return provider === 'payshack' ? status === 'success' : status === 'completed'
  }
  
  const isFailed = (row) => {
    const status = row.status.toLowerCase()
    return provider === 'payshack' ? status === 'failed' : status === 'failed'
  }
  
  const isPending = (row) => {
    const status = row.status.toLowerCase()
    return provider === 'payshack' ? 
      (status === 'initiated' || status === 'pending') : 
      (status === 'in progress' || status === 'pending')
  }

  const successful = data.filter(isSuccessful).length
  const failed = data.filter(isFailed).length
  const pending = data.filter(isPending).length
  const canceled = data.filter(row => row.status.toLowerCase() === 'canceled').length

  const successfulRevenue = data.filter(isSuccessful)
    .reduce((sum, row) => sum + row.amount, 0)
  
  const totalRevenue = data.reduce((sum, row) => sum + row.amount, 0)
  
  const conversionRate = total > 0 ? (successful / total) * 100 : 0

  // ะะฝะฐะปะธะท ะฟะพ ะฒัะตะผะตะฝะธ
  const timeAnalysis = analyzeByTime(data)
  
  // ะะฝะฐะปะธะท ะฟะพ ะผะตัะพะดะฐะผ ะพะฟะปะฐัั
  const paymentMethodStats = analyzeByPaymentMethod(data, isSuccessful, isFailed, isPending)

  return {
    total,
    successful,
    failed,
    pending,
    canceled,
    conversionRate,
    successfulRevenue,
    totalRevenue,
    averageAmount: total > 0 ? totalRevenue / total : 0,
    provider,
    timeAnalysis,
    paymentMethodStats,
    currency: provider === 'payshack' ? 'INR' : 'TRY'
  }
}

// ะะฝะฐะปะธะท ะฟะพ ะฒัะตะผะตะฝะธ
function analyzeByTime(data) {
  const hourlyStats = {}
  const dailyStats = {}
  
  data.forEach(row => {
    if (row.createdAt) {
      try {
        const date = new Date(row.createdAt)
        const hour = date.getHours()
        const day = date.toISOString().split('T')[0]
        
        // ะะพัะฐัะพะฒะฐั ััะฐัะธััะธะบะฐ
        if (!hourlyStats[hour]) {
          hourlyStats[hour] = { count: 0, revenue: 0 }
        }
        hourlyStats[hour].count++
        hourlyStats[hour].revenue += row.amount
        
        // ะะฝะตะฒะฝะฐั ััะฐัะธััะธะบะฐ
        if (!dailyStats[day]) {
          dailyStats[day] = { count: 0, revenue: 0 }
        }
        dailyStats[day].count++
        dailyStats[day].revenue += row.amount
      } catch (e) {
        // ะะณะฝะพัะธััะตะผ ะฝะตะฟัะฐะฒะธะปัะฝัะต ะดะฐัั
      }
    }
  })
  
  return { hourlyStats, dailyStats }
}

// ะะฝะฐะปะธะท ะฟะพ ะผะตัะพะดะฐะผ ะพะฟะปะฐัั
function analyzeByPaymentMethod(data, isSuccessful, isFailed, isPending) {
  const stats = {}
  
  data.forEach(row => {
    const method = row.paymentMethod || 'Unknown'
    if (!stats[method]) {
      stats[method] = { total: 0, successful: 0, failed: 0, pending: 0, revenue: 0 }
    }
    
    stats[method].total++
    stats[method].revenue += row.amount
    
    if (isSuccessful(row)) stats[method].successful++
    else if (isFailed(row)) stats[method].failed++
    else if (isPending(row)) stats[method].pending++
  })
  
  return stats
}

// WebSocket ะพะฑัะฐะฑะพัะบะฐ ะฟะพะดะบะปััะตะฝะธะน
wss.on('connection', (ws) => {
  console.log('๐ WebSocket ะบะปะธะตะฝั ะฟะพะดะบะปััะตะฝ')
  
  ws.on('message', (message) => {
    try {
      const data = JSON.parse(message)
      if (data.type === 'subscribe' && data.jobId) {
        ws.jobId = data.jobId
        console.log(`๐ก ะะปะธะตะฝั ะฟะพะดะฟะธัะฐะปัั ะฝะฐ ะทะฐะดะฐัั: ${data.jobId}`)
      }
    } catch (e) {
      console.error('ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ WebSocket ัะพะพะฑัะตะฝะธั:', e)
    }
  })
  
  ws.on('close', () => {
    console.log('๐ WebSocket ะบะปะธะตะฝั ะพัะบะปััะตะฝ')
  })
})

// Health check
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    timestamp: new Date().toISOString(),
    activeJobs: jobs.size 
  })
})

// ะะฐะฟััะบ ัะตัะฒะตัะฐ
app.listen(PORT, () => {
  console.log(`๐ Analytics API ัะตัะฒะตั ะทะฐะฟััะตะฝ ะฝะฐ ะฟะพััั ${PORT}`)
  console.log(`๐ WebSocket ัะตัะฒะตั ะทะฐะฟััะตะฝ ะฝะฐ ะฟะพััั 8080`)
  console.log(`๐ ะะพัะพะฒ ะบ ะพะฑัะฐะฑะพัะบะต ะฑะพะปััะธั CSV ัะฐะนะปะพะฒ!`)
}) 